# DashLeads - Arquitectura TÃ©cnica

## ğŸ—ï¸ VisiÃ³n General

DashLeads es una plataforma de Sales Intelligence construida con Next.js 14 (App Router), TypeScript y Prisma, enfocada en el mercado B2B espaÃ±ol del sector Horeca.

## ğŸ“Š Stack TecnolÃ³gico

### Frontend
- **Next.js 14** (App Router) - Framework React con SSR/SSG
- **React 18** - UI Library
- **TypeScript** - Type safety
- **Tailwind CSS** - Utility-first styling
- **Lucide React** - Icon library
- **Recharts** - Data visualization
- **React Leaflet** - Maps (para rutas)

### Backend
- **Next.js API Routes** - Serverless API endpoints
- **Prisma ORM** - Type-safe database access
- **SQLite** - Development database (fÃ¡cil migrar a PostgreSQL)

### Scraping
- **Axios** - HTTP client
- **Cheerio** - HTML parsing (jQuery-like)
- **Puppeteer** - Headless browser (para sitios con JS)

## ğŸ—„ï¸ Database Schema

```prisma
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prospect   â”‚ â—„â”€â”€â”
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚ id          â”‚    â”‚
â”‚ name        â”‚    â”‚
â”‚ address     â”‚    â”‚
â”‚ coordinates â”‚    â”‚
â”‚ rating      â”‚    â”‚
â”‚ leadScore   â”‚    â”‚
â”‚ missing[...]â”‚    â”‚
â”‚ current[...]â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
       â”‚           â”‚
       â”‚ 1:N       â”‚ M:N
       â–¼           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   Visit     â”‚    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚ id          â”‚    â”‚
â”‚ visitDate   â”‚    â”‚
â”‚ outcome     â”‚    â”‚
â”‚ orderValue  â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   Route     â”‚ â”€â”€â”€â”˜
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id          â”‚
â”‚ name        â”‚
â”‚ plannedDate â”‚
â”‚ optimized   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1:N
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚RouteProspect â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ routeId      â”‚
â”‚ prospectId   â”‚
â”‚ orderIndex   â”‚
â”‚ visited      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Flujo de Datos

### 1. Scraping Flow

```
Usuario â†’ Scrape Page â†’ API /scrape
                           â”‚
                           â”œâ”€> Create Scraping Job
                           â”‚
                           â”œâ”€> Google Places Scraper
                           â”‚   â””â”€> Extract: name, address, coords, rating
                           â”‚
                           â”œâ”€> TripAdvisor Scraper
                           â”‚   â””â”€> Extract: reviews, product mentions
                           â”‚
                           â”œâ”€> Product Detector
                           â”‚   â””â”€> Analyze: found products, missing products
                           â”‚
                           â”œâ”€> Lead Scorer
                           â”‚   â””â”€> Calculate: lead score (0-100)
                           â”‚
                           â””â”€> Save Prospects to DB
```

### 2. Lead Scoring Algorithm

```typescript
Lead Score = 
  Rating Score (0-30)       // Based on business rating
  + Review Score (0-20)     // Based on number of reviews
  + Gap Score (0-30)        // Number of missing products
  + Recency Score (0-20)    // Time since last contact

Max: 100 points
```

**Scoring Breakdown:**
- **Rating**: `rating * 6` (max 30)
- **Reviews**: `min(reviewCount / 10, 20)` (max 20)
- **Missing Products**: `min(count * 10, 30)` (max 30)
- **Recency**: 
  - Never contacted: 20 points
  - 90+ days: 20 points
  - 30-90 days: 10 points
  - < 30 days: 0 points

### 3. Route Optimization

```
Selected Prospects â†’ Optimize Algorithm â†’ Ordered Route
                           â”‚
                           â”œâ”€> Nearest Neighbor Algorithm
                           â”‚   1. Start from user location
                           â”‚   2. Find nearest prospect
                           â”‚   3. Move to nearest, repeat
                           â”‚
                           â”œâ”€> Calculate Total Distance
                           â”‚   â””â”€> Haversine formula
                           â”‚
                           â””â”€> Estimate Duration
                               â””â”€> 10 min/visit + 3 min/km
```

**Nearest Neighbor Algorithm:**
```typescript
function optimizeRoute(prospects, startLat, startLng) {
  const remaining = [...prospects]
  const ordered = []
  let current = { lat: startLat, lng: startLng }
  
  while (remaining.length > 0) {
    // Find nearest
    const nearest = findNearest(current, remaining)
    ordered.push(nearest)
    remaining.remove(nearest)
    current = nearest.location
  }
  
  return ordered
}
```

### 4. Product Detection

```
Menu Items â†’ Product Detector â†’ Found & Missing
                  â”‚
                  â”œâ”€> Normalize text (lowercase, remove accents)
                  â”‚
                  â”œâ”€> Check keywords for each product
                  â”‚   Example: ["heineken"] â†’ found in menu?
                  â”‚
                  â”œâ”€> Calculate confidence (0-100)
                  â”‚   Based on keyword matches
                  â”‚
                  â””â”€> Prioritize opportunities
                      - Business type matching
                      - Price range matching
                      - Category importance
```

## ğŸ¯ API Endpoints

### Prospects
```
GET    /api/prospects          # List all (with filters)
POST   /api/prospects          # Create new
GET    /api/prospects/[id]     # Get one
PATCH  /api/prospects/[id]     # Update
DELETE /api/prospects/[id]     # Delete
```

### Routes
```
GET    /api/routes             # List all routes
POST   /api/routes             # Create optimized route
GET    /api/routes/[id]        # Get route details
PATCH  /api/routes/[id]        # Update route
```

### Scraping
```
POST   /api/scrape             # Start scraping job
GET    /api/scrape?jobId=X     # Get job status
```

### Statistics
```
GET    /api/stats              # Dashboard statistics
GET    /api/stats?salesPerson=X # Per salesperson
```

### Visits
```
GET    /api/visits             # List visits
POST   /api/visits             # Log new visit
GET    /api/visits?prospectId=X # By prospect
```

## ğŸ” Scrapers Architecture

### Base Scraper Interface
```typescript
interface Scraper {
  scrapeRestaurants(config: ScraperConfig): Promise<RestaurantData[]>
}

interface ScraperConfig {
  city: string
  cuisine?: string
  limit?: number
  delayMs?: number
}
```

### Implemented Scrapers

**1. Google Places Scraper**
- Uses: Google Places API
- Returns: Basic info, coordinates, ratings
- Rate limit: 1 request/second
- Reliability: â˜…â˜…â˜…â˜…â˜…

**2. TripAdvisor Scraper**
- Uses: HTTP + Cheerio (HTML parsing)
- Returns: Reviews, ratings, product mentions
- Rate limit: 1 request/2 seconds
- Reliability: â˜…â˜…â˜…â˜…â˜† (anti-bot puede bloquear)

**3. Glovo Scraper** (En desarrollo)
- Needs: Puppeteer (JavaScript rendering)
- Returns: Full menus, prices
- Challenges: Heavy anti-bot protection
- Reliability: â˜…â˜…â˜†â˜†â˜†

### Scraping Best Practices

1. **Rate Limiting**: Siempre usar delays entre requests
2. **User Agent**: Rotar user agents para evitar detecciÃ³n
3. **Error Handling**: Graceful degradation si un scraper falla
4. **Caching**: No scraper el mismo prospect dentro de 24h
5. **Respect robots.txt**: Aunque no sea legalmente requerido

## ğŸ” Security Considerations

### Data Privacy
- No almacenamos informaciÃ³n sensible de usuarios finales
- Datos pÃºblicos (restaurantes) son scraped responsablemente
- API keys en `.env.local`, nunca en el cÃ³digo

### API Security
- Rate limiting en API endpoints (TODO)
- Input validation con Zod (TODO)
- CORS configurado apropiadamente (TODO)

### Scraping Ethics
- Delays entre requests
- Respect para tÃ©rminos de servicio
- No sobrecargar servidores
- Usar APIs oficiales cuando disponibles

## ğŸ“ˆ Escalabilidad

### Current Setup (MVP)
- SQLite database
- Serverless API routes
- Client-side rendering (CSR)
- **LÃ­mites**: ~1000 prospects, single user

### Scale to 10K Prospects
- Migrar a PostgreSQL
- Add database indexing
- Server-side rendering (SSR)
- Redis caching
- Background jobs (BullMQ)

### Scale to 100K+ Prospects
- PostgreSQL con replicaciÃ³n
- Microservices architecture
- Queue system para scraping
- CDN para assets estÃ¡ticos
- Multi-tenant architecture
- Analytics pipeline (ClickHouse)

## ğŸš€ Performance Optimizations

### Current
- âœ… Next.js automatic code splitting
- âœ… Image optimization (Next/Image)
- âœ… Static generation donde posible
- âœ… API route caching (stale-while-revalidate)

### TODO
- â³ Database query optimization (indexes)
- â³ Virtual scrolling para listas largas
- â³ Service worker para offline support
- â³ Bundle size optimization
- â³ Lazy loading de componentes pesados

## ğŸ§ª Testing Strategy (Recomendado)

```
Unit Tests
â”œâ”€ lib/utils.ts (calculateDistance, leadScore)
â”œâ”€ lib/scrapers/product-detector.ts
â””â”€ lib/scrapers/google-places.ts

Integration Tests
â”œâ”€ API routes (/api/prospects, /api/routes)
â””â”€ Scraping orchestrator

E2E Tests (Playwright)
â”œâ”€ User flow: scrape â†’ prospects â†’ route
â””â”€ Dashboard statistics
```

## ğŸ“¦ Deployment Options

### Vercel (Recomendado)
- âœ… Zero config para Next.js
- âœ… Edge functions
- âœ… Auto scaling
- âš ï¸ Serverless limits (10s timeout)

### Docker
```dockerfile
FROM node:18-alpine
# ... build steps
EXPOSE 3000
CMD ["npm", "start"]
```

### Traditional VPS
- Nginx reverse proxy
- PM2 process manager
- PostgreSQL database
- Redis cache

## ğŸ”„ Future Enhancements

### Fase 2
- [ ] Mobile app (React Native)
- [ ] Real-time updates (WebSockets)
- [ ] Email notifications
- [ ] PDF reports generation
- [ ] CSV/Excel export

### Fase 3
- [ ] Machine learning lead scoring
- [ ] Competitor analysis
- [ ] Predictive analytics
- [ ] CRM integrations (Salesforce, HubSpot)
- [ ] WhatsApp integration para follow-ups

## ğŸ“š Referencias

- [Next.js Docs](https://nextjs.org/docs)
- [Prisma Docs](https://www.prisma.io/docs)
- [Web Scraping Best Practices](https://www.scraperapi.com/blog/web-scraping-best-practices/)
- [Haversine Formula](https://en.wikipedia.org/wiki/Haversine_formula)

---

**Ãšltima actualizaciÃ³n:** Diciembre 2025



